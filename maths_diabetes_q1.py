# -*- coding: utf-8 -*-
"""maths2_q1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pdxV0Qwns8yynh8qPWS4ysaLYL2elV01
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

data = pd.read_csv('/content/Diabetes.csv')

X = data[['Chol','TG','HDL', 'LDL']].iloc[:1600].values
y = data['BMI'].iloc[:1600].values

# Linear Regression
model = LinearRegression()
model.fit(X, y)

# Parameters (coefficients)
parameters = model.coef_
#intercept = model.intercept_

# Compute predictions
predictions = model.predict(X)

# Compute empirical risk (mean squared error)
empirical_risk = mean_squared_error(y, predictions)

# Print parameters and empirical risk
print("Parameters (coefficients):", parameters)
#print("Intercept:", intercept)
print("Empirical risk (MSE):", empirical_risk)

# ii. Non-linear Regression

# Non-linear feature map function
def non_linear_feature_map(X):
    x1, x2, x3, x4 = X[:, 0], X[:, 1], X[:, 2], X[:, 3]
    phi = np.column_stack((np.ones(len(X)), x1, x1*x1, x2, x3, x4, x3*x4))
    #phi = ([1, x1, x1*x1, x2, x3, x4, x3*x4])
    return phi

# Non-linear Regression
phi = non_linear_feature_map(X)
model_non_linear = LinearRegression()
model_non_linear.fit(phi, y)

theta = np.linalg.inv(phi.T.dot(phi)).dot(phi.T).dot(y)
print("theta:", theta)
# Parameters (coefficients) for non-linear model
parameters_non_linear = model_non_linear.coef_
#intercept_non_linear = model_non_linear.intercept_

# Compute predictions for non-linear model
predictions_non_linear = model_non_linear.predict(phi)

# Compute empirical risk for non-linear model (mean squared error)
empirical_risk_non_linear = mean_squared_error(y, predictions_non_linear)

# Print parameters and empirical risk for non-linear model
print("Parameters for non-linear model:", parameters_non_linear)
#print("Intercept for non-linear model:", intercept_non_linear)
print("Empirical risk for non-linear model (MSE):", empirical_risk_non_linear)

# iv. MAP Estimation (continued)

# Assuming noise in prediction function follows normal distribution N(0, sigma^2)
# Compute sigma^2 as the empirical risk of the linear regression model
sigma_squared = empirical_risk

# Assuming training data to be last 1600 rows
training_data = data[-1600:]

# Set prior distribution for parameters following normal distribution N(theta_i, 1/100 * Identity)
prior_mean = np.append(intercept, parameters)
prior_covariance = np.eye(len(prior_mean)) / 100

# Extract relevant columns for independent variables (Chol, TG, HDL, LDL) and dependent variable (BMI)
X = data[['Chol', 'TG', 'HDL', 'LDL']].values
y = data['BMI'].values

# Consider the remaining rows as test data
X_test = X[1600:]
y_test = y[1600:]

# Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X, y)

# Predict using linear regression on test data
y_pred_linear_test = lin_reg.predict(X_test)

# Compute mean squared error for linear regression on test data
mse_linear_test = mean_squared_error(y_test, y_pred_linear_test)

# Nonlinear Regression
X_train_nonlinear = nonlinear_feature_map(X)
nonlin_reg = LinearRegression()
nonlin_reg.fit(X_train_nonlinear, y)

# Predict using nonlinear regression on test data
X_test_nonlinear = nonlinear_feature_map(X_test)
y_pred_nonlinear_test = nonlin_reg.predict(X_test_nonlinear)

# Compute mean squared error for nonlinear regression on test data
mse_nonlinear_test = mean_squared_error(y_test, y_pred_nonlinear_test)

# Output the comparison result
print("Mean Squared Error for Linear Regression on Test Data:", mse_linear_test)
print("Mean Squared Error for Nonlinear Regression on Test Data:", mse_nonlinear_test)

# Model Recommendation
if mse_linear_test < mse_nonlinear_test:
    print("Linear regression model is recommended.")
else:
    print("Nonlinear regression model is recommended.")

# iv. MAP Estimation (continued)

# Consider the last 1600 rows as training data
X_train = X[-1600:]
y_train = y[-1600:]

# Fit linear regression model on last 1600 rows
lin_reg_last = LinearRegression()
lin_reg_last.fit(X_train, y_train)

X_train_nonlinear = nonlinear_feature_map(X)
nonlin_reg_last = LinearRegression()
nonlin_reg_last.fit(X_train, y_train)

# Compute empirical risk for the last 1600 rows
empirical_risk_last = mean_squared_error(y_train, lin_reg_last.predict(X_train))
empirical_risk_last1 = mean_squared_error(y_train, nonlin_reg_last.predict(X_train))
# Compute σ^2 as the empirical risk of the regression in part i
sigma_squared = empirical_risk_last

# Compute θ_MAP parameters
theta_map = lin_reg_last.coef_  # Assuming θ_MAP = θ_MLE for simplicity

# Define the prior distribution for parameters
# prior_mean = theta_map
# prior_variance = 1/100 * np.eye(len(theta_map))  # 1/100 times the identity matrix

prior_mean = np.append(intercept, parameters)
prior_covariance = np.eye(len(prior_mean)) / 100

# Compute θ_MAP using the formula: θ_MAP = (X^T*X + (σ^2/σ0^2)*I)^(-1)*X^T*y
X_train_with_bias = np.column_stack((np.ones(len(X_train)), X_train))
X_transpose_X = np.dot(X_train_with_bias.T, X_train_with_bias)
posterior_covariance = np.linalg.inv(np.linalg.inv(prior_covariance) + (1/sigma_squared) * X_transpose_X)
posterior_mean = np.dot(posterior_covariance, np.dot(np.linalg.inv(prior_covariance), prior_mean) + (1/sigma_squared) * np.dot(X_train_with_bias.T, y_train))

# Output θ_MAP parameters
print("θ_MAP Parameters:")
for i, theta in enumerate(posterior_mean):
    print(f"θ{i+1}: {theta}")

# Compare the average error on the whole dataset for models in part i, ii, and θ_MAP
# For simplicity, let's just compare the empirical risk on the whole dataset

# Empirical risk for part i (linear regression)
print("Empirical Risk for Linear Regression (Part i):", empirical_risk_last)
print("Empirical Risk for non-Linear Regression (Part ii):", empirical_risk_last1)

# Empirical risk for part ii (nonlinear regression)
# You can use the previously computed empirical risk for nonlinear regression (empirical_risk_nonlinear)

# Empirical risk for θ_MAP
# Compute the predictions using θ_MAP on the entire dataset and then compute the empirical risk
X_with_bias = np.column_stack((np.ones(len(X)), X1))
predictions_theta_map = np.dot(X_with_bias, posterior_mean)
empirical_risk_theta_map = mean_squared_error(y, predictions_theta_map)
print("Empirical Risk for θ_MAP (Part iv):", empirical_risk_theta_map)